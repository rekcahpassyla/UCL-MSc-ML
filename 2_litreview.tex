\chapter{Background and existing work}

In this chapter we present an overview of the main ideas pertaining to this project, whose aim is to learn aligned concept embeddings for multiple domains simultaneously, then evaluate the quality of those embeddings compared to unaligned embeddings. We outline the philosophical basis for concepts, and explore why the relationships between concepts are significant. We also briefly survey different types of embeddings and their characteristics. As our hypothesis is that multimodal learning will give better results than unimodal learning, we look at the reasoning behind this hypothesis. Lastly, we define alignment both in general terms and the specific terms of this problem, and consider ways that alignment may be achieved. 

\section{Concepts}

There is a philosophical theory known as the ``representational theory of the mind" \cite{stanfordconcepts} in which concepts are defined as psychological entities that make up an internal system of representation. The relationships between concepts may form part of their definition; that is, the concepts may be implicitly defined by their relationships to other concepts as well as having explicit properties of their own. The relationship between concepts is a key theme in this project, as it is these connections that define the structure of the concept network, which is key to the alignment problem. 

The \cite{stanfordconcepts} definition is also a main definition used in cognitive science \cite{Pinker2007}. In \cite{NatureOfHumanConcepts}, concepts are related to human characterisation of categories of objects, noting that categories may overlap and have fuzzy boundaries. In \cite{GOLDSTONE2002295}, concepts are again defined not only by features (apple maps to ``red or green or yellow in colour", ``round in shape") - the ``external grounding" description of meaning, but also by their relationships to each other (``apple" is more like ``pear" but less like ``strawberry"). The ``conceptual web" description states that a concept's meaning is defined by its place within the entire structure formed by all concepts. 

In the field of computer science, there exist many frameworks of concepts defined in machine-interpretable ways. Some examples are Cyc \cite{Cyc} (an ontology of ``common-sense" rules and concepts), WordNet (a lexical database of English words, with the inherent assumption that words and concepts are interchangeable) \cite{WordNet}, and the Google Knowledge Graph \cite{KnowledgeGraphs}. These store the connections between concepts like hierarchy and inference, not just names; in this field too, we see that these relationships encode valuable information. 

There is precedent for this way of thinking in the psychological and cognitive science literature. \cite{SHEPARD19701} found that the connections between concepts (internal mental representations) should reflect the connections between the external (real world) representations; this was experimentally tested by querying subjects on the identification of US states by shape, and further confirmed by \cite{SecondOrderIsomorphismFaces}, testing the identification of faces. \cite{GOLDSTONE2002295} found an algorithm that was able to use the internal relationships between concepts from disparate systems to find correspondence between those two systems. 

\cite{CoocurrenceVisionLanguage2021} found that object representations in the human brain (which can be thought of as concepts - mental representations) are related to the co-occurrence statistics of objects occurring in images and described in language. They posit that objects occur in context, with certain objects occurring together more often than not, and that the brain possesses mechanisms to support this type of contextual knowledge. They found that brain response as measured by fMRI activity can be predicted by the co-occurrence statistics of objects within a visual scene. \cite{STANSBURY20131025} also found that the brain's response to scenes could be predicted based on clusters of co-occurring objects in that scene. 

Therefore, research evidence suggests that concepts may be considered to embody observed phenomena or events in the world, and that the relationships between concepts are important. Any machine learning system aiming to learn concepts in a similar way to humans needs to take this into account. 

\section{Embeddings}

In machine learning, embeddings are continuous real-valued vector representations of features. Language embeddings (built from textual input data) are the most commonly known type, but embeddings may be constructed from any data source. They are essentially a form of dimensionality reduction. For example, a one-hot representation of words in a corpus may have dimensionality in the millions, but converting these to word embeddings might reduce the problem dimensionality to several hundred. One of the earliest word embedding algorithms is \texttt{word2vec} \cite{word2vec}, in which a neural network is used to learn embeddings from a corpus by projecting similar words to similar locations in the target vector space. This algorithm takes advantage of co-occurrence patterns (some words occur in the neighbourhood of other words). The resulting embeddings should reflect the properties of words, where words with similar meaning are close together in embedding space. The ``Continuous Bag Of Words" (CBOW) variant uses a window of context (disregarding order) to predict the current word, and the Skip-gram variant uses the current word to predict the context window, weighted by distance from the current word. In both cases, we see that the context of the current word is important, pointing again to the relationship between the concepts being a key input for embedding creation. 

The GloVe \cite{pennington2014glove} embedding algorithm is also based on co-occurrence statistics. The co-occurrence of a word pair is the number of times those words occur within a set context window of each other. The GloVe algorithm attempts to learn embeddings whose dot products give rise to the particular co-occurrence statistics of the corpus. These algorithms can be generalised to learn embeddings from any source of co-occurrence statistics, not just words; in \cite{CoocurrenceVisionLanguage2021}, a set of object embeddings called \texttt{object2vec} was built from co-occurrence statistics from the ADE20K data set \cite{ADE20K} of images labelled by human annotators, using the \texttt{word2vec} algorithm. In this project, we do the same for the GloVe algorithm, learning embeddings from co-occurrence statistics of non-textual inputs. 

%BERT \cite{BERT}, ELMo \cite{ELMo} and fastText \cite{FastText} take the use of context one step further, in that word embeddings in these models may have different representations for the same word depending on the specific context a word is used. These capture more distant long-range connections between words. This is in contrast to GloVe and \texttt{word2vec}, in which there is only one embedding for any given word and all of its uses in every context in the corpus are taken into account when creating that single embedding. 

\cite{MikolovMachineTranslation} found that word embedding spaces have similar structure over different languages, even when those languages are linguistically quite far apart, like English and Vietnamese- another example of how the relationships between entities in the concept systems are significant. 

The Laplacian eigenmap algorithm \cite{LaplacianEigenmaps} is a geometrically motivated graph-based algorithm for learning embeddings. A weighted graph is created with a node for each concept/feature, and edges are added between nodes if they meet some definition of closeness (such as Euclidean distance, or being in the $k$-nearest neighbour set). The embeddings are the eigenvectors of the graph Laplacian. This algorithm is also context-based but in a different way; it preserves information about the entire local neighbourhood geometry. 

\subsection{Probabilistic embeddings}
Most algorithms for generating embeddings have significant stochasticity, as the learning process often involves minimising loss using stochastic gradient descent. The loss function landscapes are complex with many local minima, and the solution is sensitive to initial conditions. Therefore, runs with different random seeds will produce different embeddings; not just the individual embedding values will differ, but also the relationships between those embeddings. In a later part of this document we show examples of this. 

All of the previously mentioned embedding generation algorithms result in point estimates, which are deterministic in the sense that each embedding is a single vector of numbers. We can generalise this idea to probabilistic embeddings, in which each embedding is represented by multiple vectors that are parameters of a distribution. For example, we may consider embeddings to be multivariate Gaussians with independent dimensions (diagonal covariance matrix), therefore representing each embedding with two $n$-dimensional vectors, for the mean and variance respectively. By learning the variance as well, we derive further information about each concept that can be used to quantify the degree of uncertainty of that concept in the system. When the embeddings are used, a sample is taken from the distribution of each concept whose embedding is desired. 

\cite{ProbabilisticEmbeddingsCrossModal} represent cross-modal (visual and language) embeddings as probability distributions in an embedding space common to both modes, and use the uncertainty represented by the learned variance in automated decision making. Including the uncertainty in their information retrieval task improved performance, as well as increasing the interpretability of the final embeddings. Looking ahead to the problem of finding correspondences between embeddings in multiple domains, we also see that variance can provide additional information for disambiguation during the mapping process. 

\cite{DensityMatchingWordEmbeddings} and \cite{vilnis2015word} learn word embeddings by modeling each embedding as a probability density function. \cite{DensityMatchingWordEmbeddings} learn bilingual embeddings in an unsupervised way by matching the densities of the two monolingual embedding spaces. This allowed them to achieve state-of-the-art results on linguistically distant language pairs without the special initialisation or complicated optimisation required by many unsupervised methods. \cite{vilnis2015word} learn a mapping from individual words, as well as words in context, to a Gaussian distribution over a latent space. This mapping is such that the linguistic and semantic properties of the words are preserved by the relationships between the distributions. Words that appear in similar context should have similar embeddings. In particular, they wanted entailment relationships\footnote{If there is an entailment relationship between A and B, A must imply B.} to be represented by the means and variances of the words' respective distributions. A diagram, reproduced below from \cite{vilnis2015word}, demonstrates the concept: 

 \begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/review/entailment.png}
    \caption{
        Figure taken from \cite{vilnis2015word}. The ellipses represent the projection onto eigenvectors of the mixture means and variances of the respective words' distributions. The pattern is that items that entail other items should be substantially contained within the entailed items' ellipses. For example, Bach is a famous classical male composer, and thus the ellipse for Bach is contained (mostly) within the ellipses for all of the other words' classes. 
    }
    % generated by analyse.py 
\end{figure}

\newpage
\section{Machine learning paradigms}

\subsection{Supervised / unsupervised learning}
Supervised learning requires external labelling of data to give the system information about the ``correct" things to learn. For example, a category label for an image, or that the word ``cat" in English corresponds to ``kucing" in Malay. Unsupervised learning requires the learning system to extract regularities from the data without such guided input. There has to be some external input, for example, telling the system about the universe of available concepts, but there are fewer constraints imposed on the algorithm, which should generalise using only the data values. Semi-supervised learning falls in between, where we know ``correct" labels or categories for only some items in our dataset. 

Learning in humans comprises both types. Humans often learn by comparing their activities or ideas with known correct data, or by receiving feedback from an external agent about their correctness of their actions; this is supervised learning. Humans also learn in an unsupervised way, by making inferences from all the data available to them in different modalities such as sound, vision, and natural language. 

\subsection{Multi-task learning}

Human learning often follows the multi-task paradigm, where we apply knowledge to one task that was obtained from learning related tasks. Most of us learned arithmetic in primary school, and we apply that to checking the transactions of our bank account, or to adding up the total at the supermarket till. Basic skills are built upon to allow more complex techniques to be learned. 

The machine learning equivalent is known as multi-task learning, where more than one objective is minimised at a time, and training signals of one task can affect the signals of other tasks in the same ensemble. A synergistic effect is observed where models learned from multi-task learning tend to generalise better \cite{OverviewMultiTaskLearning}. By training on multiple tasks, the model can learn a more general representation of the pattern that underlies all those tasks. If this general representation is closer to the true universal generative representation, it will allow the model to generalise to novel tasks better (partially overcoming the bias-variance tradeoff). %Ideally, information from one task's domain should help training for other tasks on other domains.

By learning from multiple tasks simultaneously, we are using more data than we would use in learning only a single task. Training a model requires learning a good generalisation for the task that ignores the noise in the data. As different tasks have different patterns of noise, learning multiple simultaneous tasks should allow learning of a more general representation. This reduces the risk of overfitting to only one task. There is also a regularising effect as multi-task learning adds an inductive bias that makes a model favour some hypotheses over others. In the context of our embedding alignment problem, the learning of embeddings in one domain acts as an auxiliary task for the learning of embeddings in the other domain, with each domain acting as an inductive bias for the other. The end result should induce the model to favour hypotheses that explain both tasks, with the hope that this model is more representative of the ``ground truth" of the real world that generates their co-occurrence statistics.  

\section{Alignment and ways to achieve it}
    
\subsection{Some definitions of alignment}

\subsubsection{Alignment as mapping two spaces to a single latent space}
In its simplest form, alignment requires learning to map between two vector spaces. The notation from \cite{ManifoldLearningTheoryAndApplications} is used here to state the problem, as we find it particularly clear.

If there are two datasets $X$ and $Y$ whose instances all lie on the same underlying manifold $Z$, one version of the alignment problem requires finding functions $f$ and $g$ such that $f(x_i)$ is close  to $g(y_j)$, for some problem-specific definition of distance.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/review/alignment.png}
    \caption{
        Figure taken from \cite{ManifoldLearningTheoryAndApplications}. The $\vecX$ and $\vecY$ spirals denote the two datasets, with the center line showing the data points embedded into the shared space, with local similarity relations being preserved. $f$ and $g$ denote the functions mapping $\vecX$ and $\vecY$ respectively into the shared space. 
    }
    % generated by analyse.py 
\end{figure}

If $f(x_i) = g(y_j)$, then $x_i$ and $y_j$ are in correspondence. If we know ahead of time that $x_i$ and $y_j$ are analogous points in their datasets, then we can provide this information to the algorithm that is trying to infer $f$ and $g$. The union of the ranges of $f$ and $g$ is then the joint latent space. This can be generalised to more than two datasets. 

This however is a definition that maps both domains into the same space. 

\subsubsection{Alignment as learning mappings from one domain to another}

In the previous definition, alignment requires that both domains be mapped to a single latent domain. This can be useful for certain problems, for example, to find a single language-independent representation of the data in multilingual related corpora. 

There is another definition for alignment, which requires only that domains can be mapped to each other directly. 

\begin{figure}[H]
\label{fig:alignment2}
    \centering
    \includegraphics[width=\textwidth]{images/review/alignment2.png}
    \caption{
        The $\vecX$ and $\vecY$ spirals still denote the two datasets, but this time $f$ and $g$ denote the functions mapping $\vecX$ and $\vecY$ respectively to each other, instead of into some shared space.
    }
    % generated by analyse.py 
\end{figure}

We wish to find mappings $f(\vecX) \rightarrow \vecY$ and $g(\vecY) \rightarrow \vecX$ where the spaces $\vecX$ and $\vecY$  have similar structures. This is slightly different from the definition of alignment in the previous section. This definition may be used when it is not clear what the dimensionality of the latent space should be. 

We will use this definition of alignment in our problem, as we indeed do not know what an appropriate dimensionality should be for a latent space that represents data from both domains. 

\subsubsection{Second order isomorphism}

Returning to an idea first raised in \cite{SHEPARD19701}, we want second order isomorphism- we want to know the functional relationships between clusters of concepts over our two modalities. Even if there is no structural resemblance between a concept and that concept's representation, the same structure should be observed between the relationships between the concepts  and the representations. As stated by \cite{GOLDSTONE2002295}, the meaning of a concept is tied to its relationships to other concepts in the same network. Similarity relationships between concepts within the same system can therefore be used to map between systems; using only these relationships, \cite{GOLDSTONE2002295} found an algorithm, ABSURDIST, that was able to translate between two such networks. Without constraints on the systems, or even on the number of concepts in each system, ABSURDIST was able to find translations using only similarity matrices created by some external agent (for example, a German-English bilingual human). ABSURDIST found that, while within-system relationships are enough to find a translation, this translation can be made more robust to noise by adding external, extrinsic information about correspondences (for example, higher weights for certain correspondences). This is a concrete example of why the relationships between concepts are important; because they can be used to perform alignment. 

\cite{GOLDSTONE2002295} found that ABSURDIST's mappings were better for systems that had a greater number of elements. This is because such a system has more similarity relations, and each similarity relation provides a constraint to uniquely identify each member. Therefore, systems with more elements are more constrained. 

\subsubsection{Applications of alignment problems}

Some other examples of alignment problems spanning a range of applications are given below.  

\begin{itemize}
    \item Biological manifold alignment: \cite{magan} applies Generative Adversarial Networks \cite{GAN} to the problem of alignment of cell correspondence between cytometry batches (knowing which cells generated which biological results). 
    \item Neural style transfer: \cite{CycleGAN} takes as input differently styled source and target image sets and applies adversarial network techniques to translate images from the source set style into the target set style. 
    \item Bilingual lexical induction: \cite{wordtranslationwithoutparalleldata} applies unsupervised alignment between monolingual word representations to derive a dictionary between those languages.
    \item Deep multimodal embedding: \cite{DeepMultimodalEmbedding} relates information from three modalities- point-cloud, natural language and manipulation trajectory data, to teach a robot arm  how to manipulate new objects. 
\end{itemize}

\subsection{Methods for concept alignment}

In this section, the following notation applies:

\begin{equation*}
\begin{split}
    &\vecX \medspace \text{denotes embeddings in the source domain},\\
    &\vecY \medspace \text{denotes embeddings in the target domain},\\
    &\vecW \medspace \text{denotes a transformation matrix}.\\
\end{split}
\end{equation*}

\subsubsection{Regression and related models}

Regression models are the simplest form of alignment model. They only require learning a transformation matrix $\vecW$ from one domain to another (minimising the mean squared loss $|| (\vecW \vecX + \vecb) - \vecY||_2^2$) which can then be applied to a new source vector to map into the target space. \cite{MikolovMachineTranslation} uses this to find a ``translation matrix" that can map from word embeddings in one language space to another. Orthogonal models constrain the learned $\vecW$ matrix to be orthogonal, which is appropriate if the angles between embeddings are more important as a measure of similarity than the distances between them. Various standard preprocessing steps may be applied like normalisation to unit norm / mean centering, decorrelation to have unit variance, or SVD for dimension reduction.

Maximum margin models are similar to the support vector machine \cite{SVM} in that they balance increasing the weights from matching pairs with reducing the weights learned from known generated noise pairs. An example loss function (reproduced from \cite{kalinowski2020survey}) is:

\begin{equation*}
\begin{split}
\sumin \sum_{j \neq i}^{k} &\max \{0, \gamma - \cos(\vecW \vece_i^s, \vece_i^t) + \cos(\vecW \vece_i^s, \vece_j^t)\}\\
\spaced{with}& \vece_i, \vece_j \lspaced{being the $i$th and $j$th of $n$ embeddings},\\
& \vecW \lspaced{being the transformation matrix},\\
& k \lspaced{being the number of noise pairs}, \\
& \lspaced{and}\medspace \gamma \lspaced{being the margin parameter}.
\end{split}
\end{equation*}

This is different from regression models which rely largely on minimising the mean-squared error. \cite{Hubness} found that this form of loss reduced the effect of hubs that can plague regression and orthogonal algorithms. Hubs are embeddings with high similarity to all other embedding vectors in the space, due to entities that are too common (such as words that are very frequent in a corpus) or simply as an artifact of the transformation where many features get mapped to a small region of embedding space spuriously. \cite{ImprovingSupervisedBilingualMapping} introduce another metric to reduce hubness, cross-domain similarity local scaling, that incorporates the mean of $k$-nearest neighbour distances of points in the target space to capture the neighbourhood geometry. 

Point set registration, most commonly found in computer vision, is the alignment problem applied to sets of points in 2 or 3 dimensions. \cite{PointSetRegistrationReview} reviews many current techniques; one key difference between this problem and the general alignment problem is that the points are known to lie on a 2- or 3-dimensional manifold, and this is quite a significant constraint. We cannot make any such assumptions about the dimensionality of our embeddings. 

\subsubsection{Manifold alignment models}

As stated in \cite{ManifoldLearningTheoryAndApplications}, manifold alignment is a type of constrained simultaneous dimensionality reduction with the aim of finding a low-dimensional embedding for all input datasets that preserves the topology of correspondences between them. The datasets may have disjoint features. The data may be of very high dimension, but if all the data points lie on a low-dimensional manifold, this manifold may be learnable.  

This requires the multiple datasets to be representable by a shared underlying structure. It may be convenient to learn the mappings between datasets without ever formalising this shared structure, or it may be useful to find common features. For example, in language translation it may be enough to know the mappings from words or phrases in one language to the equivalent entities in another language. However if the problem is multilingual information retrieval, it may be more useful to express the translations of different documents as a single underlying joint representation. Our specific problem is learning aligned embeddings from co-occurrence data that represent the statistics of how concepts occur in different human-created media. If we consider the ultimate underlying generative process of all these media to be ``the real world", it is plausible that the embeddings could have some underlying shared joint representation, but we do not know anything about this representation, particularly the dimensionality of the underlying process. 

Some existing dimensionality reduction techniques that can be used in alignment are the Isomap \cite{Isomap}, which reduces dimension while preserving distances between points; locally linear embedding \cite {LocallyLinearEmbedding}, which reduces dimension while keeping distances the same between local neighbourhoods; and the previously mentioned Laplacian eigenmap \cite{LaplacianEigenmaps}, which approximates the manifold by the adjacency graph derived from the embeddings. These algorithms all try to find a low dimensional representation of a single dataset, and manifold alignment simply uses these or similar algorithms to find embeddings for multiple datasets simultaneously. Without correspondence information, manifold alignment will result in independent embeddings for each input dataset, but if direct correspondence information is provided, or a means for inferring it, manifold alignment will use this to constrain the embeddings to be aligned. Manifold alignment considers each individual dataset to be part of one larger dataset whose range includes the mapped values of all other datasets. 

In \cite{UnsupervisedAlignmentWP}, an approach to aligning two sets of existing embeddings (learned separately from the alignment procedure) using a combination of Procrustes analysis and the Wasserstein distance is described. Procrustes analysis is normally used to learn an affine transformation between two sets of points with a known correspondence. If we consider $\vecX \in \R^{n \times d}$ ($n$ vectors of dimension $d$) and $\vecY \in \R^{n \times d}$ (another set of vectors of the same size), the Procrustes linear transformation is the solution to the following:

\begin{equation*}
    \argmin{\vecW \in \R^{d \times d}} \quad  ||\vecX \vecW - \vecY||_2^2
\end{equation*}

\cite{Goodall1991ProcrustesMI} used this to analyse two-dimensional shapes, where the shapes are considered to be the same if by application of rotation, translation and isotropic scaling, one can be transformed to the other. \cite{MikolovMachineTranslation} applied this technique to learn linear mappings between word embeddings in different languages using a bilingual dictionary. 

The Wasserstein distance, also known as the Earth Mover Distance, is the solution of the following optimisation problem

\begin{equation}
\label{eq:wasserstein}
\begin{split}
    &\argmin{\vecP \in \mathscr{P}_n} \quad || \vecX - \vecP \vecY ||_2^2 \\
    \spaced{where}&\mathscr{P}_n = \{\vecP \in \{0, 1\}^{n \times n}, \vecP \one_n = \one_n, \vecP^T \one_n = \one_n \}
\end{split}
\end{equation}

where $\vecP$ denotes a permutation matrix. It enforces a one-to-one mapping from the rows of $\vecX$ to $\vecY$.

%If the source and target embeddings $\vecX$ and $\vecY$ are thought of as probability distributions, $\mathscr{P}_n$ denotes a permutation matrix that moves mass from $\vecX$ to create $\vecY$. 

\cite{Zhang2017EarthMD} used this distance measure as a minimisation objective to perform automated translation without supervision. By using the Wasserstein distance as a measure of closeness between the source and target embedding spaces, they formulate a system in which minimisation of this distance draws the two distributions closer. %The translation problem faced by \cite{Zhang2017EarthMD} did not have a one-to-one mapping between symbols, because some symbols in one space map to one symbol in the other space, therefore the minimisation of the objective had to be considered over the whole distribution. 

%\cite{UnsupervisedAlignmentWP} combined both Procrustes analysis and the Wasserstein distance, to solve the following optimisation problem:

%\begin{equation*}
%\begin{split}
%\argmin{\vecQ \in \mathscr{O}_d} \quad \argmin{\vecP \in \mathscr{P}_n }\quad || \vecX \vecQ - \vecP \vecY||_2^2
%\end{split}
%\end{equation*}

%where $\vecQ$ is an orthogonal matrix. In order to practically solve this optimisation, they developed a novel stochastic algorithm to minimise a convex relaxation of this problem, details of which are omitted here. 

\subsubsection{Graph matching and graph similarity methods}

A system of interconnected concepts can be represented as a graph whose nodes represent concepts and whose edges represent relationships between concepts. For example, in \cite{Absurdist2}, such a system is represented as a directed graph with $N$ nodes whose edges are connected with labels from the set $S$ representing all combinations of possible relationships between any two nodes. Examples of such relations are ``Similar to", ``Is-A" or other hyponymic / synonymic relationships, or weights corresponding to the degree of co-occurrence of the two concepts. \cite{Absurdist2}, a sequel to \cite{GOLDSTONE2002295}, further describes how alignment of two conceptual systems may be formalised as matching two graphs.

The general graph isomorphism problem, that of telling if two graphs represent the same structure, is NP-hard \cite{GraphIsomorphismNPHard}. As cited in \cite{Absurdist2}, much work has been done in the field of finding approximate isomorphisms; finding a function $s(.)$ such that for two graphs $G_1$ and $G_2$, the distance between $s(G_1)$ and $s(G_2)$ is minimised, where $s$ is a problem-specific distance measure. There are polynomial-time algorithms for certain subtypes of graphs or trees, but in general heuristic algorithms are the only practical possibilities. 

The ABSURDIST II algorithm described in \cite{Absurdist2} creates a matrix of feasible translations between the two concept graphs which is iteratively updated based on the similarity between distances between elements of the system. At the end of the iterations, the output is a correspondence matrix that describes the strength of correspondence between elements of the source and target sets; this is used to create the mapping from source to target items. 

The \texttt{torch-two-sample} Python library and its corresponding paper \cite{torchtwosample} introduce smoothed versions of some graph-based similarity measures, such as the Friedman-Rafsky test \cite{friedmanrafsky} and a version of k-nearest neighbours \cite{torchtwosample}, that can be used as loss functions for learning similar graph structures. These are not actual graph isomorphism methods as they do not directly provide an alignment mapping between the two graphs; rather, they aim to provide distributional similarity metrics based on graph-based properties. These are converted to smooth functions by taking the statistics to be expectations of a probability distribution, thus allowing implementations to be used as loss functions trainable by backpropagation. Further details may be found in the appendix (\ref{appendix:graphbased}). 

\subsubsection{Generative adversarial networks}

The ``generative" part of a generative adversarial model is a function (usually learned by a deep learning network) that outputs samples from a distribution indistinguishable from a particular source dataset. A discriminator model is then trained against the generated outputs so that it learns to tell the difference between real and synthetic outputs; this is the ``adversarial" part. By alternating the training of these two models, the generator learns to produce better and better samples. In effect, the generator is learning to produce samples from the manifold on which the input data lies. This model was first introduced in \cite{GAN} and while the main objective is usually to generate new samples from a given distribution, there are examples where it has been used for alignment.

The Manifold Alignment GAN \cite{magan} attempts to alleviate some of the problems with traditional GANs, one of them being that generated items can fool the discriminator at a batch level because the two manifolds are superimposed, rather than being aligned. When the manifolds are superimposed rather than aligned, it is as if the ``edges" of the manifolds match, but the points within may be in any position (see Figure \ref{fig:magan}). If we were to overlay the manifolds, the corresponding points would not overlap. There are an exponential number of possible mappings that result in overlapping but unaligned manifolds. 


\begin{figure}[H]
\label{fig:magan}
    \centering
    \includegraphics[width=\textwidth]{images/review/magan.png}
    \caption{
        This diagram taken from \cite{magan} illustrates the conceptual difference between datasets that are merely superimposed (left panels), and datasets that are aligned (right panels). The MAGAN attempts to find pointwise correspondence between cells in one cytometry batch and another. 
    }
\end{figure}

The MAGAN introduces a correspondence loss that measures the distance between a data point and its mapped image in the other domain, as well as the reconstruction loss (difference between an original point and its reconstructed image after going through both generators). %It also uses the mini-batch discrimination technique described in \cite{ImprovedTechniquesTrainingGANS} to prevent mode collapse, where all inputs get mapped to the same embedding by the generator.

%\cite{wordtranslationwithoutparalleldata} presents an adversarial method for learning cross-lingual word embeddings without supervision (without knowing beforehand any correspondences between the languages). If we consider the usual notation of $\vecX$ being the source embedding space and $\vecY$ being the target embedding space, the objective is to learn $\vecW$ such that $\vecW \vecX$ and $\vecY$ are as similar as possible. The discriminator is trained to distinguish between random samples from $\vecW \vecX$ and $\vecY$, while the generator is trained to learn $\vecW$ to prevent the discriminator from predicting accurately. They found however that the adversarial method alone did not yield better results than the supervised baseline. Therefore they also adopted a refinement procedure using Procrustes analysis to further improve the learned $\vecW$. They found that the adversarial approach would try to align all words even if they are not frequent, but the embeddings for rare words are then less frequently updated. Since the learned mapping is linear ($\vecW \vecX$) it would make sense to learn the mapping using only the most frequent words and refine afterwards. They also used the cross-domain similarity local scaling metric, which uses nearest neighbour information of each embedding to provide additional information to the optimisation.

CycleGAN \cite{CycleGAN} is not specifically an alignment model, but contains useful ideas for our purposes. CycleGAN is intended to provide image-to-image translation, where given two unordered image collections, one can be ``translated" into the style of the other. For example, transforming pictures in the style of Monet into photographic style images. CycleGAN contains two GANs; one learns a mapping $f$ from the input set $\vecX$ to the target set $\vecY$, and one learns the mapping $g$ which maps $\vecY$ to $\vecX$. A key part of the CycleGAN model is the cycle consistency loss, which for the domain $\vecX$ is $f(g(\vecY)) - \vecX$ (there is an equivalent cycle consistency loss going the other way). This loss is intended to induce $f$ and $g$ to be consistent with each other; the MAGAN model also uses this loss, calling it ``reconstruction loss". The cycle consistency / reconstruction loss is intended to reduce the possibility of the learned mapping distribution matching the output distribution, but individual inputs not being mapped to individual outputs. This is a different way of expressing the alignment problem. 

Certain types of datasets are better suited as inputs to GANs. Datasets with large numbers of object classes are not suited to GANs, which tend to underestimate the entropy in the distribution \cite{ImprovedTechniquesTrainingGANS}. Many GAN implementations take images as input, and generally the input datasets are very large, providing many samples from which to learn the appropriate distribution. Our particular dataset could be considered to have only one stimulus per concept, if we take all concepts as end nodes in the taxonomy tree.  Additionally, the salient features of images are more likely to lie on 2- or 3-dimensional manifolds. We do not know the appropriate dimensionality for the distribution that would represent any underlying manifold the concept embeddings may lie on; if the dimension of the GAN's latent space is not adequate, it will not be able to explore the sample space well, and learning will not occur. 

\section{Summary}
Regression or other similar solely linear algebra-based techniques are not suitable, as our source and target embeddings are of very different size (19996 concepts vs 526 concepts with an intersection of 230 concepts). While there is a one-to-one mapping between the concepts in the intersection of source and target domains, the size of this intersection set is small relative to the number of concepts in each domain, and many concepts would be unaccounted for. 

Manifold alignment techniques dependent on mapping both domains to a shared latent space are also not considered, as we do not know anything about the dimension of this space and the wrong choice of dimensionality would greatly affect any algorithm chosen.

Graph matching, being NP-hard, is not likely to be feasible as one of our domains has 19996 concepts forming a complex network. Any techniques from computer vision / point set registration are unlikely to work because of the previously mentioned constraint that most of those points will lie on a 2- or 3-dimensional manifold. 

Generative adversarial networks work best when the input datasets meet certain criteria (outlined in the previous section), which ours do not. However, some of the loss functions used in various GAN architectures are of interest to us, and we will make use of them when designing our approach. 

