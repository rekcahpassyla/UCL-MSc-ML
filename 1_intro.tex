\chapter{Introduction}
\todo[inline]{Not many references here- just a brief outline of the main ideas to be encountered. More detail in the next chapter}

\section{Concepts}

There is a philosophical theory known as the ``representational theory of the mind" \cite{stanfordconcepts} in which concepts are defined as psychological entities that make up an internal system of representation. These concepts have relationships with each other that may form part of their definition; that is, the concepts may be implicitly defined by their relationships to other concepts as well as intrinsic explicit properties of their own. 

There is often a one-to-one mapping between concepts and words (in human natural language). However, the different human languages often have different levels of expressiveness when it comes to concepts. For example, there are words in different languages that do not have immediate translations in others; the German word ``schadenfreude" does not translate to a single word in English, instead requiring a longer sentence. The Malay word ``merajuk"  may be translated into English as ``sulking", but ``merajuk" conveys additional emotional tone of the type of sulking usually associated with a petulant child. Therefore we see that concepts may not always be standardised between people and cultures, and one human's ``concept vocabulary" may not overlap completely with another's. 

Different types of media (for example text, images and audio) provide different representations of the same concepts. It is reasonable to conclude that if these media represent human-generated embodiments of concepts, the underlying generative process should manifest in similar statistics of what concepts occur in which content. 

In machine learning, we can  also describe concepts as statistical regularities in the world \cite{RoadsLoveNatureMachineIntelligence}. It is often desirable to extract these computational representations as multidimensional embeddings- that is, sequences of $d$-dimensional numbers. When doing so, we want to capture these statistical regularities in a way that preserves the relationships between these concepts \cite{RoadsLoveNatureMachineIntelligence}. Ideally, to mimic human cognitive behaviour, we wish to learn computational representations in such a way that the representations learnt from different domains (for example images and audio) should have similar structures. For example, pictures of apples are more likely to contain pictures of pears or oranges than of violins and buses, and documents containing the word 'apple' are more likely to have the word 'pear' in close proximity compared to the words 'violin' or 'bus', so we would like embeddings learnt from images and text to display the behaviour that ``apple" is closer to ``pear" than to ``violin" or ``bus". 

There is evidence \cite{CoocurrenceVisionLanguage2021} that the human brain stores these statistical co-occurrence regularities  as part of its representation of objects (and concepts), and that response to an object stimulus (visual or text) can be predicted by the category in which that object resides. Hence, this is an appropriate basis for considering machine learning approaches that seek to imitate the mechanisms of human learning. 

In this project, we use machine learning algorithms to learn numerical representations that map to individual concepts, with the input data coming from data of different media types. We will examine the relationships between these numerical representations with an eye towards examining their correspondence with human representations of such concepts. 
%It has been found that the human brain can encode the context surrounding a visual object \cite{CoocurrenceVisionLanguage2021}- that is, information about what other objects are commonly found with that item, and that brain response to an object could be predicted by the category in which that object resided. The same authors also found that language (text) stimuli  

%\emph{Concepts as relationships \cite{GOLDSTONE2002295} - conceptual web}[Include items about relationships between concepts]

%[Tie this into concept learning in ML and how it must take into account the relationships between concepts]


\section{Learning}
In machine learning, there is the distinction between supervised and unsupervised learning. Supervised learning requires external labelling of data to give the system information about the ``correct" things to learn. For example, a category label, or that the word ``cat" maps to the word ``kucing" in Malay, or that two images are both of apples. Unsupervised learning requires the learning system to extract the regularities from the data without such guided input. There has to be some external input, for example telling the system that the vocabulary of available concepts contains the labels ``cat", ``apple" and ``violin", but there are fewer constraints imposed on the algorithm, which should generalise using only the data values. 

Learning in humans comprises both types. Humans often learn by comparing their activities or ideas with known correct data, or by being given feedback by an external agent about their correctness of their actions; this is supervised learning. Humans also learn in an unsupervised way, by making inferences from all the data available to them in different modalities such as sound, vision, and natural language. 

Intellectually it is an interesting problem to create computational systems that learn like humans, as it may give insights into the mechanisms of learning (of both humans and computational systems). Humans naturally learn from multiple input streams, and knowledge acquired from learning one particular task is also applied to other tasks, which is the main point of most human education systems. \todo{can find a citation for this?}. The machine learning equivalent is known as multi-task learning, where more than one objective is minimised at a time, and training signals of one task can affect the losses of other tasks in the same ensemble. A synergistic effect is observed where models learned from multi-task learning tend to generalise better \cite{OverviewMultiTaskLearning}.

\section{Alignment}

As alluded to previously, it is reasonable to consider that the structure of a concept network (whether represented in the human brain or in computational form) should be similar regardless of the modality of the input data. Therefore, it is another interesting problem to consider how concepts may be learnt from multiple modalities in a way that preserves this similarity; when concepts are learnt from images or audio, the two concept structures should have the same relationships between individual concepts. Finding the mapping from one concept in one system to its analogue in another system is known as alignment. 

Alignment may be done before or after learning of concepts. If it is done after learning, the methodology involves learning concepts separately from multiple modalities, and then further learning a transformation from one domain's concepts to the other, or learning transformations from both domain concepts to an intermediate representation. If alignment is done during the learning process, then the concepts are learnt jointly, with no post-processing to achieve alignment. 

Alignment of concepts has various applications in machine learning, amongst them and certainly not limited to machine translation, object alignment in video, transfer learning, knowledge graph matching and text understanding. \todo{NEEDS CITATIONS FOR EACH} The generic problem is one of finding correspondences between regularities in one dataset and regularities in another dataset. 

\section{Project objectives}
In this project we wish to learn concepts represented as multidimensional vectors known as embeddings. The input data originates from two input modalities, and a key aim is to try to jointly learn embeddings that are aligned, as in the previous definition. Both deterministic and probabilistic embeddings are learnt, with deterministic embeddings having each concept represented by a single vector, and probabilistic embeddings representing each concept by two vectors, one for the mean and one for the variance. We will examine the learnt means and variances, as well as compare the learnt aligned embeddings to a human similarity metric. Comparing with human judgement is an important part of evaluation, as we are interested in algorithms that learn in similar ways to humans. 

The dataset used will be co-occurrence data constructed from the Google Open Images (19996 concepts) and AudioSet (526 concepts) datasets (cite). A full description of the dataset will follow in a later chapter; this dataset contains a total of 20292 concepts with an overlap of 230. The overlapping concepts will be used in semi-supervised alignment. We note that this dataset is quite unbalanced; there are almost 40 times more concepts in Open Images than in AudioSet. 

\subsection{Key points}
\begin{itemize}
    \item Probabilistic embeddings and analysis of variance related to concepts in terms of level of abstraction and hierarchy
    \item Techniques for joint learning of aligned embeddings from different modalities of real datasets, both semi-supervised and unsupervised
    \item The effectiveness of different distributional distance metrics in learning joint alignment \todo{MAYBE TAKE THIS OUT}
    \item The difficulties inherent in alignment of embeddings learnt from real co-occurrence data from multiple modalities. 
\end{itemize}
