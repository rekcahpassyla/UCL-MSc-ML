\chapter{Introduction}

\section{Concepts}

There is a philosophical theory known as the ``representational theory of the mind" \cite{stanfordconcepts} in which concepts are defined as psychological entities that make up an internal system of representation. The relationships between concepts may form part of the definition of those concepts; that is, the concepts may be implicitly defined by their relationships to other concepts as well as having explicit properties of their own. 

There is often a one-to-one mapping between concepts and words (in human natural language). However, the different human languages often have different levels of expressiveness when it comes to concepts. For example, there are words in some languages that do not have immediate translations in others; the German word ``schadenfreude" does not translate to a single word in English, instead requiring a longer sentence. The noun ``biscuit" has different meanings for American and British people. Therefore we see that concepts may not always be standardised between people and cultures, and one human's ``concept vocabulary" may not overlap completely with another's. 

Different types of media (for example text, images and audio) provide different representations of the same concepts. It is reasonable to conclude that if these media represent human-generated embodiments of concepts, the underlying generative process should manifest in the statistics of what concepts occur in which content. 

In machine learning, we can  also describe concepts as statistical regularities in the world \cite{RoadsLoveNatureMachineIntelligence}. It is often desirable to extract these computational representations as multidimensional embeddings- that is, sequences of $d$-dimensional real numbers. When doing so, we want to capture these statistical regularities in a way that preserves the relationships between these concepts. Ideally, to mimic human cognitive behaviour, we wish to learn computational representations in such a way that the representations learned from different domains (for example images and audio) should have similar structures. For example, pictures of apples are more likely to contain pictures of pears or oranges than of violins and buses, and documents containing the word ``apple" are more likely to have the word ``pear" in close proximity compared to the words ``violin" or ``bus"- so we would like embeddings learned from images and text to display the behaviour that ``apple" is closer to ``pear" than to ``violin" or ``bus". We see that the shape of the network formed by the embeddings is significant. 

There is evidence \cite{CoocurrenceVisionLanguage2021} that the human brain stores these statistical co-occurrence regularities  as part of its representation of objects (and concepts), and that response to an object stimulus (visual or text) can be predicted by the category in which that object resides. Hence, this is an appropriate basis for considering machine learning approaches that seek to emulate the mechanisms of human learning. 

In this project, we use machine learning algorithms to learn numerical representations of individual concepts, with the input data originating from different media types. We will examine how the relationships between these numerical representations correspond to the relationships between human representations of such concepts. 

\section{Learning}
In machine learning, a distinction is made between supervised and unsupervised learning. Supervised learning requires external labelling of data to give the system information about the ``correct" things to learn. For example, a category label of positive or negative, or that the word ``cat" maps to the word ``kucing" in Malay, or that two images are both of apples. Unsupervised learning requires the learning system to extract the regularities from the data without such guided input. There has to be some external input, for example telling the system that the vocabulary of available concepts contains the labels ``cat", ``apple" and ``violin", but there are fewer constraints imposed on the algorithm, which should generalise using only the data values. Semi-supervised learning falls in between, where we know ``correct" labels or categories for only some items in our dataset. 

Learning in humans comprises both types. Humans often learn by comparing their activities or ideas with known correct data, or by being given feedback by an external agent about their correctness of their actions; this is supervised learning. Humans also learn in an unsupervised way, by making inferences from all the data available to them in different modalities such as sound, vision, and natural language. 

By creating computational systems that learn like humans, we may gain insights into the mechanisms of learning (of both humans and computational systems). Humans naturally learn from multiple input streams, and knowledge acquired from learning one particular task is also applied to other tasks, which is the main point of most human education systems. The machine learning equivalent is known as multi-task learning, where more than one objective is minimised at a time, and training signals of one task can affect the losses of other tasks in the same ensemble. A synergistic effect is observed where models learned from multi-task learning tend to generalise better \cite{OverviewMultiTaskLearning}.

\section{Alignment}

As alluded to previously, it is reasonable to consider that the structure of a concept network (whether represented in the human brain or in a computer program) should be similar regardless of the form of the input data. We now consider how concepts may be learned from multiple modalities in a way that preserves this similarity; when concepts are learned from images or audio, the two resulting structures should have the same relationships between individual concepts. Finding the mapping from a concept in one system to its analogue in another system is known as alignment. 

Alignment may be done before or after learning of concepts. If done after learning, the methodology involves learning concepts separately from multiple input datasets, and then further learning a transformation from one domain's concepts to the other, or learning transformations from both domain's concepts to a single intermediate representation. If alignment is done during the learning process, then the concepts are learned jointly, with no post-processing to achieve alignment. 

Alignment of concepts has various applications in machine learning, amongst them and not limited to machine translation, object alignment in video, transfer learning, knowledge graph matching and text understanding. The generic problem is one of finding correspondences between regularities over multiple datasets. 

\section{Project objectives}
In this project we wish to learn concepts represented as multidimensional vectors known as embeddings. The input data originates from two modalities- images and audio, and a key aim is to jointly learn embeddings that are aligned, so that we know the correspondences between domains, as in the previous definition. Both deterministic and probabilistic embeddings are learned, with deterministic embeddings having each concept represented by a single vector, and probabilistic embeddings representing each concept by two vectors, one for the mean and one for the variance. We will examine the learned means and variances, as well as compare the learned aligned embeddings to human similarity metrics. Comparing with human judgement is an important part of evaluation, as we are interested in algorithms that learn in similar ways to humans. 

The dataset used consists of co-occurrence matrices constructed from the Google Open Images (19996 concepts) \cite{openimages} and AudioSet (526 concepts) \cite{audioset} datasets. A full description of the dataset will follow in a later chapter; this dataset contains a total of 20292 concepts with an overlap of 230. The concepts present in both domains will be used to perform semi-supervised alignment. We note that this dataset is quite unbalanced; there are almost 40 times more concepts in Open Images than in AudioSet. 

\subsection{Key points}
\begin{itemize}
    \item Learning of probabilistic embeddings and analysis of variance related to concepts in terms of level of abstraction and hierarchy.
    \item Techniques for joint learning of aligned embeddings from different modalities of real datasets, both semi-supervised and unsupervised.
    \item The role of a distributional distance metric in improving learning of joint alignment.
    \item The difficulties inherent in alignment of embeddings learned from real co-occurrence data from multiple modalities. 
\end{itemize}
